{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Generator\n",
    "\n",
    "This notebook is used for generating submission files for the Trendyol E-Commerce Hackathon. It includes steps for making predictions with the trained model and formatting the output for submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Local score validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import-libraries"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from catboost import CatBoostClassifier\n",
    "from tqdm import tqdm\n",
    "from metrics.trendyol_custom_auc_stub import score\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Ignore FutureWarnings to keep output clean\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "def _print(msg: str):\n",
    "    print(f\"[local test] {msg}\")\n",
    "\n",
    "\n",
    "def time_based_val_split(df_pl: pl.DataFrame, val_frac: float = 0.15) -> pd.DataFrame:\n",
    "\n",
    "    if \"ts_hour\" in df_pl.columns and df_pl[\"ts_hour\"].dtype != pl.Datetime:\n",
    "        df_pl = df_pl.with_columns(pl.col(\"ts_hour\").str.to_datetime())\n",
    "    df_pl = df_pl.sort(\"ts_hour\")\n",
    "    split_idx = int(len(df_pl) * (1 - val_frac))\n",
    "    return df_pl[split_idx:].to_pandas()\n",
    "\n",
    "\n",
    "def build_features(df: pd.DataFrame) -> list[str]:\n",
    "    targets = [\"ordered\", \"clicked\"]\n",
    "    exclude_cols = set(targets + [\n",
    "        \"ts_hour\",\n",
    "        \"session_id\",\n",
    "        \"content_creation_date\",\n",
    "        \"update_date\",\n",
    "        \"added_to_cart\",\n",
    "        \"added_to_fav\"\n",
    "    ])\n",
    "    return [c for c in df.columns if c not in exclude_cols]\n",
    "\n",
    "\n",
    "def predict_scores(models_dir: Path, df: pd.DataFrame, features: list[str]) -> tuple[np.ndarray, np.ndarray]:\n",
    "    mo_p = models_dir / \"model_ordered_local.cbm\"\n",
    "    mc_p = models_dir / \"model_clicked_local.cbm\"\n",
    "    if not mo_p.exists() or not mc_p.exists():\n",
    "        raise FileNotFoundError(f\"Missing model file: {mo_p if not mo_p.exists() else mc_p}\")\n",
    "    model_o = CatBoostClassifier(); model_o.load_model(str(mo_p))\n",
    "    model_c = CatBoostClassifier(); model_c.load_model(str(mc_p))\n",
    "    p_order = model_o.predict_proba(df[features])[:, 1]\n",
    "    p_click = model_c.predict_proba(df[features])[:, 1]\n",
    "    return p_order, p_click\n",
    "\n",
    "\n",
    "# Metric helper (clean version without prior warning)\n",
    "def local_metric(val_pd: pd.DataFrame, scores: np.ndarray) -> float:\n",
    "    tmp = val_pd.copy()\n",
    "    tmp[\"final_score\"] = scores\n",
    "    \n",
    "    # Group once for efficiency\n",
    "    solution_groups = tmp.groupby('session_id')\n",
    "    \n",
    "    # Build ordered / clicked / all item strings\n",
    "    ordered_items = solution_groups.apply(lambda g: ' '.join(g.loc[g['ordered'] == 1, 'content_id_hashed'].astype(str)))\n",
    "    clicked_items = solution_groups.apply(lambda g: ' '.join(g.loc[g['clicked'] == 1, 'content_id_hashed'].astype(str)))\n",
    "    all_items = solution_groups['content_id_hashed'].apply(lambda s: ' '.join(s.astype(str)))  # More direct\n",
    "    \n",
    "    # Combine into solution frame\n",
    "    val_solution = pd.DataFrame({\n",
    "        'ordered_items': ordered_items,\n",
    "        'clicked_items': clicked_items,\n",
    "        'all_items': all_items\n",
    "    }).reset_index()\n",
    "\n",
    "    val_submission = (\n",
    "        tmp.sort_values(['session_id', 'final_score'], ascending=[True, False])\n",
    "        .groupby('session_id')['content_id_hashed']\n",
    "        .apply(lambda s: ' '.join(s.astype(str)))\n",
    "        .reset_index()\n",
    "        .rename(columns={'content_id_hashed': 'prediction'})\n",
    "    )\n",
    "    return score(val_solution, val_submission, 'session_id')\n",
    "\n",
    "\n",
    "def run(root: Path, w: float | None):\n",
    "    models_dir = root / \"models/local\"\n",
    "    train_path = root / \"data/train_data_v5.parquet\"\n",
    "\n",
    "    val_pl = pl.read_parquet(str(train_path))\n",
    "\n",
    "    val_pd = time_based_val_split(val_pl, val_frac=0.15)\n",
    "    _print(f\"Split into train/val: {len(val_pd)}\")\n",
    "\n",
    "    features = build_features(val_pd)\n",
    "\n",
    "    _print(\"Predicting on validationâ€¦\")\n",
    "    p_order_val, p_click_val = predict_scores(models_dir, val_pd, features)\n",
    "\n",
    "    # --- Weight search over validation set ---\n",
    "    _print(\"Searching for best ensemble weight w on validation set...\")\n",
    "    \n",
    "    best_s = 0.0\n",
    "    best_w = 0.7  # Default fallback\n",
    "    \n",
    "    # Weight search space (increase number of points for finer search)\n",
    "    search_space = np.linspace(0.1, 0.9, 1)\n",
    "    \n",
    "    for w_candidate in tqdm(search_space, desc=\"Searching for best w\"):\n",
    "        scores = w_candidate * p_order_val + (1.0 - w_candidate) * p_click_val\n",
    "        s_candidate = local_metric(val_pd, scores)\n",
    "        _print(f\"  -> w={w_candidate:.3f} | Local Score={s_candidate:.5f}\")  # Optional per-step log\n",
    "        if s_candidate > best_s:\n",
    "            best_s = s_candidate\n",
    "            best_w = w_candidate    \n",
    "\n",
    "    _print(f\"Optimal weight found: w = {best_w:.3f} (local score = {best_s:.5f})\")\n",
    "\n",
    "def parse_args():\n",
    "    p = argparse.ArgumentParser()\n",
    "    p.add_argument(\"--w\", type=float, default=0.70, help=\"Weight for ordered proba; default 0.70 (no grid-search)\")\n",
    "    return p.parse_args()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    root = Path(\"C:/Projects/trendyol\")\n",
    "    run(root, args.w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Submission File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "from catboost import CatBoostClassifier\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Ignore FutureWarnings to keep output clean\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "\n",
    "def _print(msg: str):\n",
    "    print(f\"[create submission file] {msg}\")\n",
    "\n",
    "\n",
    "def build_features(df: pd.DataFrame) -> list[str]:\n",
    "    targets = [\"ordered\", \"clicked\"]\n",
    "    exclude_cols = set(targets + [\n",
    "        \"ts_hour\",\n",
    "        \"session_id\",\n",
    "        \"content_creation_date\",\n",
    "        \"update_date\",\n",
    "        \"added_to_cart\",\n",
    "        \"added_to_fav\"\n",
    "    ])\n",
    "    return [c for c in df.columns if c not in exclude_cols]\n",
    "\n",
    "\n",
    "def predict_scores(models_dir: Path, df: pd.DataFrame, features: list[str]) -> tuple[np.ndarray, np.ndarray]:\n",
    "    mo_p = models_dir / \"model_ordered_real.cbm\"\n",
    "    mc_p = models_dir / \"model_clicked_real.cbm\"\n",
    "    if not mo_p.exists() or not mc_p.exists():\n",
    "        raise FileNotFoundError(f\"Missing model file: {mo_p if not mo_p.exists() else mc_p}\")\n",
    "    model_o = CatBoostClassifier(); model_o.load_model(str(mo_p))\n",
    "    model_c = CatBoostClassifier(); model_c.load_model(str(mc_p))\n",
    "    p_order = model_o.predict_proba(df[features])[:, 1]\n",
    "    p_click = model_c.predict_proba(df[features])[:, 1]\n",
    "    return p_order, p_click\n",
    "\n",
    "\n",
    "\n",
    "def run(root: Path, w: float | None):\n",
    "    models_dir = root / \"models/real\"\n",
    "\n",
    "    test_path = root / \"data/test_data_v5.parquet\"\n",
    "    test_pl = pl.read_parquet(str(test_path))\n",
    "\n",
    "    val_pd = pl.read_parquet(str(root / \"data/train_data_v5.parquet\")).to_pandas()\n",
    "\n",
    "    features = build_features(val_pd)\n",
    "\n",
    "    # Use chosen / overridden weight\n",
    "    w = 0.45 # Choosen by using local score validation\n",
    "    _print(f\"Using weight w = {w:.3f} for test set predictions.\")\n",
    "\n",
    "    test_pd = test_pl.to_pandas()\n",
    "\n",
    "    p_order_t, p_click_t = predict_scores(models_dir, test_pd, features)\n",
    "    test_pd['final_score'] = w * p_order_t + (1.0 - w) * p_click_t\n",
    "    sub = (\n",
    "        test_pd.sort_values(['session_id', 'final_score'], ascending=[True, False])\n",
    "        .groupby('session_id')['content_id_hashed']\n",
    "        .apply(lambda s: ' '.join(s.astype(str)))\n",
    "        .reset_index()\n",
    "        .rename(columns={'content_id_hashed': 'prediction'})\n",
    "    )\n",
    "    out = root / \"submission.csv\"\n",
    "    sub.to_csv(out, index=False)\n",
    "    _print(f\"Saved submission: {out}\")\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    p = argparse.ArgumentParser()\n",
    "    p.add_argument(\"--w\", type=float, default=0.70, help=\"Weight for ordered proba; default 0.70 (no grid-search)\")\n",
    "    return p.parse_args()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parse_args()\n",
    "    root = Path(\"C:/Projects/trendyol\")\n",
    "    run(root, args.w)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
