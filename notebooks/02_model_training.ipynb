{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "This notebook focuses on training the machine learning model using the prepared data. It includes steps for selecting features, training the model, and evaluating its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Local Model for quickly test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "def _print(msg: str):\n",
    "    print(f\"[train CatBoostClassifier local] {msg}\")\n",
    "\n",
    "\n",
    "def load_cat_features_list(root: Path) -> list[str]:\n",
    "    p = root / \"cat_features.json\"\n",
    "    if p.exists():\n",
    "        try:\n",
    "            return json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "        except Exception:\n",
    "            pass\n",
    "    return []\n",
    "\n",
    "\n",
    "def main():\n",
    "    root = Path(\"C:/Projects/trendyol/data\")\n",
    "    # Prefer v2_plus if exists, else fall back to v2\n",
    "    train_path= root / \"train_data_v5.parquet\"\n",
    "\n",
    "    features_importance_dir = root / \"models/local/features_importance\"\n",
    "    features_importance_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    out_dir = root / \"models/local\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    _print(f\"Loading train parquet… {train_path}\")\n",
    "    df_pl = pl.read_parquet(str(train_path))\n",
    "    _print(f\"Loaded {len(df_pl)} rows.\")\n",
    "\n",
    "    # Data splitting based on time\n",
    "    if \"ts_hour\" in df_pl.columns and df_pl[\"ts_hour\"].dtype != pl.Datetime:\n",
    "        df_pl = df_pl.with_columns(pl.col(\"ts_hour\").str.to_datetime())\n",
    "    df_pl = df_pl.sort(\"ts_hour\")\n",
    "    split_idx = int(len(df_pl) * 0.85)\n",
    "    train_pl, val_pl = df_pl[:split_idx], df_pl[split_idx:]\n",
    "    train_pd = train_pl.to_pandas()\n",
    "    val_pd = val_pl.to_pandas()\n",
    "\n",
    "    # Targets and features\n",
    "    targets = [\"ordered\", \"clicked\"]\n",
    "    exclude_cols = set(targets + [\n",
    "        \"ts_hour\",\n",
    "        \"session_id\",\n",
    "        \"content_creation_date\",\n",
    "        \"update_date\",\n",
    "        \"added_to_cart\",\n",
    "        \"added_to_fav\"\n",
    "    ])\n",
    "    features = [c for c in train_pd.columns if c not in exclude_cols]\n",
    "\n",
    "    # Cat features from file if available\n",
    "    cat_features_list = load_cat_features_list(root)\n",
    "    # Fallback: infer by dtype\n",
    "    if not cat_features_list:\n",
    "        for c in features:\n",
    "            if str(train_pd[c].dtype) in (\"object\", \"string\", \"string[python]\"):\n",
    "                cat_features_list.append(c)\n",
    "\n",
    "    _print(f\"n_features={len(features)}, n_cats={len(cat_features_list)}\")\n",
    "\n",
    "    # Split targets\n",
    "    X_train = train_pd[features]\n",
    "    y_order_train = train_pd[\"ordered\"]\n",
    "    y_click_train = train_pd[\"clicked\"]\n",
    "\n",
    "    # Base params\n",
    "    base_params = dict(\n",
    "        iterations=5000,\n",
    "        eval_metric=\"AUC\",\n",
    "        loss_function=\"Logloss\",\n",
    "        task_type=\"GPU\",\n",
    "        random_seed=42,\n",
    "        verbose=100,\n",
    "        learning_rate=0.025183,\n",
    "        early_stopping_rounds=200\n",
    "    )\n",
    "\n",
    "    # ordered model\n",
    "    _print(\"Training CatBoost for 'ordered'…\")\n",
    "    order_pos = max(1, int(y_order_train.sum()))\n",
    "    order_neg = max(1, int((y_order_train == 0).sum()))\n",
    "    order_spw = order_neg / order_pos\n",
    "\n",
    "    params_ordered = base_params | {\"scale_pos_weight\": order_spw}\n",
    "    model_ordered = CatBoostClassifier(**params_ordered, cat_features=cat_features_list)\n",
    "    model_ordered.fit(X_train, y_order_train, eval_set=(val_pd[features], val_pd[\"ordered\"]), use_best_model=True)\n",
    "    ordered_path = out_dir / \"model_ordered_local.cbm\"\n",
    "    model_ordered.save_model(str(ordered_path))\n",
    "    _print(f\"Saved: {ordered_path}\")\n",
    "\n",
    "    # Feature importance as a DataFrame and save in a format that works\n",
    "    fi = model_ordered.get_feature_importance(prettified=False)\n",
    "    df_fi = pd.DataFrame({\"feature\": features, \"importance\": fi})\n",
    "    df_fi = df_fi.sort_values(\"importance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Prefer parquet, fallback to CSV if parquet not available, always also save JSON\n",
    "\n",
    "    df_fi.to_json(str(features_importance_dir / \"importance_ordered.json\"), orient=\"records\", lines=True)\n",
    "    print(\"_\" * 80)\n",
    "    # clicked model\n",
    "    _print(\"Training CatBoost for 'clicked'…\")\n",
    "    click_pos = max(1, int(y_click_train.sum()))\n",
    "    click_neg = max(1, int((y_click_train == 0).sum()))\n",
    "    click_spw = click_neg / click_pos\n",
    "\n",
    "    params_clicked = base_params | {\"scale_pos_weight\": click_spw}\n",
    "    model_clicked = CatBoostClassifier(**params_clicked, cat_features=cat_features_list)\n",
    "    model_clicked.fit(X_train, y_click_train, eval_set=(val_pd[features], val_pd[\"clicked\"]), use_best_model=True)\n",
    "    clicked_path = out_dir / \"model_clicked_local.cbm\"\n",
    "    model_clicked.save_model(str(clicked_path))\n",
    "    _print(f\"Saved: {clicked_path}\")\n",
    "\n",
    "    # Feature importance as a DataFrame and save in a format that works\n",
    "    fi = model_clicked.get_feature_importance(prettified=False)\n",
    "    df_fi = pd.DataFrame({\"feature\": features, \"importance\": fi})\n",
    "    df_fi = df_fi.sort_values(\"importance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Prefer parquet, fallback to CSV if parquet not available, always also save JSON\n",
    "\n",
    "    df_fi.to_json(str(features_importance_dir / \"importance_clicked.json\"), orient=\"records\", lines=True)\n",
    "    _print(\"Done.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Real model for competition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "def _print(msg: str):\n",
    "    print(f\"[train CatBoostClassifier real] {msg}\")\n",
    "\n",
    "\n",
    "def load_cat_features_list(root: Path) -> list[str]:\n",
    "    p = root / \"cat_features.json\"\n",
    "    if p.exists():\n",
    "        try:\n",
    "            return json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "        except Exception:\n",
    "            pass\n",
    "    return []\n",
    "\n",
    "\n",
    "def main():\n",
    "    root = Path(\"C:/Projects/trendyol\")\n",
    "    # Prefer v2_plus if exists, else fall back to v2\n",
    "    train_path= root / \"data/train_data_v5.parquet\"\n",
    "\n",
    "    features_importance_dir = root / \"models/real/features_importance\"\n",
    "    features_importance_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    out_dir = root / \"models/real\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    _print(f\"Loading train parquet… {train_path}\")\n",
    "    df_pl = pl.read_parquet(str(train_path))\n",
    "    _print(f\"Loaded {len(df_pl)} rows.\")\n",
    "\n",
    "    train_pd = df_pl.to_pandas()\n",
    "\n",
    "    # Targets and features\n",
    "    targets = [\"ordered\", \"clicked\"]\n",
    "    exclude_cols = set(targets + [\n",
    "        \"ts_hour\",\n",
    "        \"session_id\",\n",
    "        \"content_creation_date\",\n",
    "        \"update_date\",\n",
    "        \"added_to_cart\",\n",
    "        \"added_to_fav\"\n",
    "    ])\n",
    "    features = [c for c in train_pd.columns if c not in exclude_cols]\n",
    "\n",
    "    # Cat features from file if available\n",
    "    cat_features_list = load_cat_features_list(root)\n",
    "    # Fallback: infer by dtype\n",
    "    if not cat_features_list:\n",
    "        for c in features:\n",
    "            if str(train_pd[c].dtype) in (\"object\", \"string\", \"string[python]\"):\n",
    "                cat_features_list.append(c)\n",
    "\n",
    "    _print(f\"n_features={len(features)}, n_cats={len(cat_features_list)}\")\n",
    "\n",
    "    # Split targets\n",
    "    X_train = train_pd[features]\n",
    "    y_order_train = train_pd[\"ordered\"]\n",
    "    y_click_train = train_pd[\"clicked\"]\n",
    "\n",
    "    # Base params\n",
    "    base_params = dict(\n",
    "        loss_function=\"Logloss\",\n",
    "        task_type=\"GPU\",\n",
    "        random_seed=42,\n",
    "        verbose=100,\n",
    "        learning_rate=0.025183\n",
    "    )\n",
    "\n",
    "    # ordered model\n",
    "    _print(\"Training CatBoost for 'ordered'…\")\n",
    "    order_pos = max(1, int(y_order_train.sum()))\n",
    "    order_neg = max(1, int((y_order_train == 0).sum()))\n",
    "    order_spw = order_neg / order_pos\n",
    "\n",
    "    params_ordered = base_params | {\"scale_pos_weight\": order_spw, \"iterations\": 486}\n",
    "    model_ordered = CatBoostClassifier(**params_ordered, cat_features=cat_features_list)\n",
    "    model_ordered.fit(X_train, y_order_train)\n",
    "    ordered_path = out_dir / \"model_ordered_real.cbm\"\n",
    "    model_ordered.save_model(str(ordered_path))\n",
    "    _print(f\"Saved: {ordered_path}\")\n",
    "\n",
    "    # Feature importance as a DataFrame and save in a format that works\n",
    "    fi = model_ordered.get_feature_importance(prettified=False)\n",
    "    df_fi = pd.DataFrame({\"feature\": features, \"importance\": fi})\n",
    "    df_fi = df_fi.sort_values(\"importance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Prefer parquet, fallback to CSV if parquet not available, always also save JSON\n",
    "\n",
    "    df_fi.to_json(str(features_importance_dir / \"importance_ordered.json\"), orient=\"records\", lines=True)\n",
    "    print(\"_\" * 80)\n",
    "    # clicked model\n",
    "    _print(\"Training CatBoost for 'clicked'…\")\n",
    "    click_pos = max(1, int(y_click_train.sum()))\n",
    "    click_neg = max(1, int((y_click_train == 0).sum()))\n",
    "    click_spw = click_neg / click_pos\n",
    "\n",
    "    params_clicked = base_params | {\"scale_pos_weight\": click_spw, \"iterations\": 1421}\n",
    "    model_clicked = CatBoostClassifier(**params_clicked, cat_features=cat_features_list)\n",
    "    model_clicked.fit(X_train, y_click_train)\n",
    "    clicked_path = out_dir / \"model_clicked_real.cbm\"\n",
    "    model_clicked.save_model(str(clicked_path))\n",
    "    _print(f\"Saved: {clicked_path}\")\n",
    "\n",
    "    # Feature importance as a DataFrame and save in a format that works\n",
    "    fi = model_clicked.get_feature_importance(prettified=False)\n",
    "    df_fi = pd.DataFrame({\"feature\": features, \"importance\": fi})\n",
    "    df_fi = df_fi.sort_values(\"importance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Prefer parquet, fallback to CSV if parquet not available, always also save JSON\n",
    "\n",
    "    df_fi.to_json(str(features_importance_dir / \"importance_clicked.json\"), orient=\"records\", lines=True)\n",
    "    _print(\"Done.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
